{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLM6o1DSjcXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import datetime\n",
        "import os\n",
        "import os.path\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ7QF4YbN1Pl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "fb1c388d-348b-433a-dbe1-8b0a31acb23a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "%cd /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MdEuFt0nkmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 32\n",
        "# Number of training epochs\n",
        "num_epochs = 200\n",
        "LOAD_MODEL = True\n",
        "\n",
        "#PATH='/AUGMENTATION_GAN/gan_models/epoch_200/p_virus_200_2020-08-22_15:49:13.dat' #P_vir_200_opt\n",
        "#PATH='/AUGMENTATION_GAN/gan_models/epoch_200/p_bacteria_200_2020-08-22_16:21:47.dat' #P_bac_200_opt\n",
        "#PATH='/AUGMENTATION_GAN/gan_models/epoch_200/normal_200_2020-08-22_16:38:52.dat' #Normal_200_opt\n",
        "#PATH='/AUGMENTATION_GAN/gan_models/epoch_200/covid_200_2020-08-22_16:58:21.dat' #Covid_200_opt\n",
        "\n",
        "TRAIN_ALL = False\n",
        "#All images will be resized to this size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 1\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.002\n",
        "lr_d = 0.0002\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "# Beta2 hyperparam for Adam optimizers\n",
        "beta2 = 0.999\n",
        "\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "# Input to generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device) #batch of 64\n",
        "# Define Loss function\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHXGFAtBHH4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4uvXCj5zzNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Generator(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(Generator, self).__init__()\n",
        "#         self._model = nn.Sequential(\n",
        "#             # input is Z, going into a convolution\n",
        "#             #i/p,o/p,kernel size,stride,padding\n",
        "#             nn.ConvTranspose2d( nz, ngf * 16, 4, 1, 0, bias=False),\n",
        "#             nn.BatchNorm2d(ngf * 16),\n",
        "#             nn.ReLU(True),\n",
        "#             # state size. (ngf*16) x 4 x 4\n",
        "#             nn.ConvTranspose2d( ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ngf * 8),\n",
        "#             nn.ReLU(True),\n",
        "#             # state size. (ngf*8) x 8 x 8\n",
        "#             nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ngf * 4),\n",
        "#             nn.ReLU(True),\n",
        "#             # state size. (ngf*4) x 16 x 16\n",
        "#             nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ngf * 2),\n",
        "#             nn.ReLU(True),\n",
        "#             # state size. (ngf*2) x 32 x 32\n",
        "#             nn.ConvTranspose2d( ngf*2, nc, 4, 2, 1, bias=False),\n",
        "#             nn.Tanh()\n",
        "#             # state size. (nc) x 64 x 64\n",
        "#         )\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         return self._model(input)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEb5BlY5GO4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Discriminator(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(Discriminator, self).__init__()\n",
        "#         self._model = nn.Sequential(\n",
        "#             # input is (nc) x 64 x 64\n",
        "#             nn.Conv2d(nc, ndf * 2, 4, 2, 1, bias=False),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             # state size. (ndf*2) x 32 x 32\n",
        "#             nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ndf * 4),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             # state size. (ndf*4) x 16 x 16\n",
        "#             nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ndf * 8),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             # state size. (ndf*8) x 8 x 8\n",
        "#             nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ndf * 16),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             # state size. (ndf*16) x 4 x 4\n",
        "#             nn.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False),\n",
        "#             nn.Sigmoid()\n",
        "#         )\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         return self._model(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVLWLMetCrGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(name, train_epoch, values, path, save):\n",
        "    clear_output(wait=True)\n",
        "    plt.close('all')\n",
        "    fig = plt.figure()\n",
        "    fig = plt.ion()\n",
        "    fig = plt.subplot(1, 1, 1)\n",
        "    fig = plt.title('epoch: %s -> %s: %s' % (train_epoch, name, values[-1]))\n",
        "    fig = plt.ylabel(name)\n",
        "    fig = plt.xlabel('train_set')\n",
        "    fig = plt.plot(values)\n",
        "    fig = plt.grid()\n",
        "    get_fig = plt.gcf()\n",
        "    fig = plt.draw()  # draw the plot\n",
        "    fig = plt.pause(1)  # show it for 1 second\n",
        "    if save:\n",
        "        now = datetime.datetime.now()\n",
        "        get_fig.savefig('%s/%s_%.3f_%d_%s.png' %\n",
        "                        (path, name, train_epoch, values[-1], now.strftime(\"%Y-%m-%d_%H:%M:%S\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHGbk-t3imrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(generator, discriminator, gen_optimizer, dis_optimizer, metrics, num_epochs):\n",
        "    now = datetime.datetime.now()\n",
        "    g_losses = metrics['train.G_losses'][-1]\n",
        "    d_losses = metrics['train.D_losses'][-1]\n",
        "    name = \"%+.3f_%+.3f_%d_%s.dat\" % (g_losses, d_losses, num_epochs, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    fname = os.path.join('.', 'augGAN/model', name)\n",
        "    states = {\n",
        "            'state_dict_generator': generator.state_dict(),\n",
        "            'state_dict_discriminator': discriminator.state_dict(),\n",
        "            'gen_optimizer': gen_optimizer.state_dict(),\n",
        "            'dis_optimizer': dis_optimizer.state_dict(),\n",
        "            'metrics': metrics,\n",
        "            'train_epoch': num_epochs,\n",
        "            'date': now.strftime(\"%Y-%m-%d_%H:%M:%S\"),\n",
        "    }\n",
        "    torch.save(states, fname)\n",
        "    path='augGAN/plots/train_%+.3f_%+.3f_%s'% (g_losses, d_losses, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    try:\n",
        "      os.mkdir(os.path.join('.', path))\n",
        "    except Exception as error:\n",
        "      print(error)\n",
        "\n",
        "    plot('G_losses', num_epochs, metrics['train.G_losses'], path, True)\n",
        "    plot('D_losses', num_epochs, metrics['train.D_losses'], path, True)\n",
        "    plot('D_x', num_epochs, metrics['train.D_x'], path, True)\n",
        "    plot('D_G_z1', num_epochs, metrics['train.D_G_z1'], path, True)\n",
        "    plot('D_G_z2', num_epochs, metrics['train.D_G_z2'], path, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn5d4tccMIyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "def train_gan(generator, discriminator, gen_optimizer, dis_optimizer, train_loader, num_epochs, metrics):\n",
        "        iters = 0\n",
        "        print(\"GAN training started :D...\")\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(\"Epoch %d\" %(epoch+1))\n",
        "            # For each batch in the dataloader\n",
        "            for i, data in enumerate(tqdm(train_loader, 0)):\n",
        "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "                ## Train with all-real batch\n",
        "                discriminator.zero_grad()\n",
        "                # Format batch\n",
        "                b_real = data[0].to(device)\n",
        "                b_size = b_real.size(0)\n",
        "                label = torch.full((b_size,), real_label, device=device)\n",
        "                # Forward pass real batch through D\n",
        "                output = discriminator(b_real).view(-1)\n",
        "                # Calculate loss on all-real batch\n",
        "                errD_real = criterion(output, label)\n",
        "                # Calculate gradients for D in backward pass\n",
        "                errD_real.backward()\n",
        "                D_x = output.mean().item()\n",
        "                metrics['train.D_x'].append(D_x)\n",
        "\n",
        "                ## Train with all-fake batch\n",
        "                # Generate batch of latent vectors\n",
        "                noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "                # Generate fake image batch with G\n",
        "                fake = generator(noise)\n",
        "                label.fill_(fake_label)\n",
        "                # Classify all fake batch with D\n",
        "                output = discriminator(fake.detach()).view(-1)\n",
        "                # Calculate D's loss on the all-fake batch\n",
        "                errD_fake = criterion(output, label)\n",
        "                # Calculate the gradients for this batch\n",
        "                errD_fake.backward()\n",
        "                D_G_z1 = output.mean().item()\n",
        "                metrics['train.D_G_z1'].append(D_G_z1)\n",
        "                # Add the gradients from the all-real and all-fake batches\n",
        "                errD = errD_real + errD_fake\n",
        "                # Update D\n",
        "                dis_optimizer.step()\n",
        "                # if i>0:\n",
        "                #     if errD.item()>G_losses[i-1]:\n",
        "                #         dis_optimizer.step()\n",
        "                # else:\n",
        "                #     dis_optimizer.step()\n",
        "\n",
        "                # (2) Update G network: maximize log(D(G(z)))\n",
        "                generator.zero_grad()\n",
        "                label.fill_(real_label)  # fake labels are real for generator cost\n",
        "                # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "                output = discriminator(fake).view(-1)\n",
        "                # Calculate G's loss based on this output\n",
        "                errG = criterion(output, label)\n",
        "                # Calculate gradients for G\n",
        "                errG.backward()\n",
        "                D_G_z2 = output.mean().item()\n",
        "                metrics['train.D_G_z2'].append(D_G_z2)\n",
        "                # Update G\n",
        "                gen_optimizer.step()\n",
        "\n",
        "                # Save Losses for plotting later\n",
        "                G_losses.append(errG.item())\n",
        "                D_losses.append(errD.item())\n",
        "                metrics['train.G_losses'].append(errG.item())\n",
        "                metrics['train.D_losses'].append(errD.item())\n",
        "\n",
        "                # Check how the generator is doing by saving G's output on fixed_noise\n",
        "                if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
        "                    with torch.no_grad():\n",
        "                        fake = generator(fixed_noise).detach().cpu()\n",
        "                    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "                iters += 1\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch+1, num_epochs, i, len(train_loader),\n",
        "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        save_model(generator, discriminator, gen_optimizer, dis_optimizer, metrics, num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPHMkQQKJItb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_indices(dataset, class_name, indices):\n",
        "    j = 0\n",
        "    for i in range(len(dataset.targets)):\n",
        "        if dataset.targets[i] == class_name:\n",
        "            indices.append(i)\n",
        "            j += 1\n",
        "    print(\"Total Samples of class\", class_name,\"found are\",j)\n",
        "    return indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekCtxRmkLl5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test1(generator, discriminator, num_epochs, metrics):\n",
        "    print('Testing Block.........')\n",
        "    now = datetime.datetime.now()\n",
        "    g_losses = metrics['train.G_losses'][-1]\n",
        "    d_losses = metrics['train.D_losses'][-1]\n",
        "    path='augGAN/output_images'\n",
        "    try:\n",
        "      os.mkdir(os.path.join('.', path))\n",
        "    except Exception as error:\n",
        "      print(error)\n",
        "\n",
        "    test_img_list = []\n",
        "    test_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "    test_fake = generator(test_noise).detach().cpu()\n",
        "    test_img_list.append(vutils.make_grid(test_fake, padding=2, normalize=True))\n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "    fig = plt.axis(\"off\")\n",
        "    fig = plt.title(\"Fake Images\")\n",
        "    fig = plt.imshow(np.transpose(test_img_list[-1],(1,2,0)))\n",
        "    get_fig = plt.gcf()\n",
        "    fig = plt.show()\n",
        "    get_fig.savefig('%s/image_%.3f_%.3f_%d_%s.png' %\n",
        "                    (path, g_losses, d_losses, num_epochs, now.strftime(\"%Y-%m-%d_%H:%M:%S\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjQZEYmqSRyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test2(generator, discriminator, num_epochs, metrics, loader):\n",
        "    print('Testing Block.........')\n",
        "    now = datetime.datetime.now()\n",
        "    g_losses = metrics['train.G_losses'][-1]\n",
        "    d_losses = metrics['train.D_losses'][-1]\n",
        "    path='augGAN/output_images'\n",
        "    try:\n",
        "      os.mkdir(os.path.join('.', path))\n",
        "    except Exception as error:\n",
        "      print(error)\n",
        "\n",
        "    real_batch = next(iter(loader))\n",
        "    \n",
        "    test_img_list = []\n",
        "    test_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "    test_fake = generator(test_noise).detach().cpu()\n",
        "    test_img_list.append(vutils.make_grid(test_fake, padding=2, normalize=True))\n",
        "\n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "    ax1 = plt.subplot(1,2,1)\n",
        "    ax1 = plt.axis(\"off\")\n",
        "    ax1 = plt.title(\"Real Images\")\n",
        "    ax1 = plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "    ax2 = plt.subplot(1,2,2)\n",
        "    ax2 = plt.axis(\"off\")\n",
        "    ax2 = plt.title(\"Fake Images\")\n",
        "    ax2 = plt.imshow(np.transpose(test_img_list[-1],(1,2,0)))\n",
        "    #ax2 = plt.show()\n",
        "    fig.savefig('%s/image_%.3f_%.3f_%d_%s.png' %\n",
        "                    (path, g_losses, d_losses, num_epochs, now.strftime(\"%Y-%m-%d_%H:%M:%S\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncRL2jjtN-Ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_fake(generator, discriminator, metrics, n_images, folname):\n",
        "    now = datetime.datetime.now()\n",
        "    g_losses = metrics['train.G_losses'][-1]\n",
        "    d_losses = metrics['train.D_losses'][-1]\n",
        "    #path='augGAN/output_images/%+.3f_%+.3f_%d_%s'% (g_losses, d_losses, n_images, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    path='main_folder/'+str(n_images)+'/'+folname\n",
        "    try:\n",
        "      os.mkdir(os.path.join('.', path))\n",
        "    except Exception as error:\n",
        "      print(error)\n",
        "\n",
        "    im_batch_size = 50\n",
        "    #n_images=100\n",
        "    for i_batch in range(0, n_images, im_batch_size):\n",
        "        gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n",
        "        gen_images = generator(gen_z)\n",
        "        dis_result = discriminator(gen_images).view(-1)\n",
        "        images = gen_images.to(\"cpu\").clone().detach()\n",
        "        images = images.numpy().transpose(0, 2, 3, 1)\n",
        "        for i_image in range(gen_images.size(0)):\n",
        "            save_image(gen_images[i_image, :, :, :], os.path.join(path, \n",
        "                        f'image_{i_batch+i_image:04d}.png'), normalize= True)\n",
        "\n",
        "    print('Testing Block.........')\n",
        "    print('Discriminator_mean: ', dis_result.mean().item())\n",
        "    #import shutil\n",
        "    #shutil.make_archive('images', 'zip', './augGAN/output_images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWeXmdInu38z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67931a1e-780f-427d-b963-43b0b461417c"
      },
      "source": [
        "for func in [\n",
        "    lambda: os.mkdir(os.path.join('.', 'augGAN')),\n",
        "    lambda: os.mkdir(os.path.join('.', 'augGAN/model')),\n",
        "    lambda: os.mkdir(os.path.join('.', 'augGAN/plots')),\n",
        "    lambda: os.mkdir(os.path.join('.', 'augGAN/output_images'))]:  # create directories\n",
        "  try:\n",
        "    func()\n",
        "  except Exception as error:\n",
        "    print(error)\n",
        "    continue\n",
        "\n",
        "METRIC_FIELDS = [\n",
        "    'train.D_x',\n",
        "    'train.D_G_z1',\n",
        "    'train.D_G_z2',\n",
        "    'train.G_losses',\n",
        "    'train.D_losses',\n",
        "]\n",
        "metrics = {field: list() for field in METRIC_FIELDS}\n",
        "\n",
        "if nc==1:\n",
        "    mu = (0.5)\n",
        "    sigma = (0.5)\n",
        "    transform = transforms.Compose([#transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.Grayscale(num_output_channels=1),\n",
        "                                    transforms.Resize((64,64)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mu, sigma)])\n",
        "elif nc==3:\n",
        "    mu = (0.5,0.5,0.5)\n",
        "    sigma = (0.5,0.5,0.5)\n",
        "    #Originally authors used just scaling\n",
        "    transform = transforms.Compose([#transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.Resize((64,64)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mu, sigma)])\n",
        "else:\n",
        "    print(\"Tranformation not defined for this option\")\n",
        "\n",
        "data_dir = '/AUGMENTATION_GAN/custom_covid_dataset/'\n",
        "\n",
        "trainset0 = datasets.ImageFolder(os.path.join(\n",
        "          data_dir, \"train/\"), transform=transform)\n",
        "trainset500 = datasets.ImageFolder(os.path.join(\n",
        "          data_dir, \"train_classic/500/\"), transform=transform)\n",
        "trainset1000 = datasets.ImageFolder(os.path.join(\n",
        "          data_dir, \"train_classic/1000/\"), transform=transform)\n",
        "trainset2000 = datasets.ImageFolder(os.path.join(\n",
        "          data_dir, \"train_classic/2000/\"), transform=transform)\n",
        "listtrainset_no_aug = [trainset0]\n",
        "listtrainset_classic = [trainset500,trainset1000]#,trainset2000]\n",
        "listtrainset = listtrainset_no_aug + listtrainset_classic\n",
        "train_set = torch.utils.data.ConcatDataset(listtrainset)\n",
        "\n",
        "# train_set = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform=transform)\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "gen_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "dis_optimizer = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, beta2))\n",
        "\n",
        "if LOAD_MODEL:\n",
        "    if torch.cuda.is_available():\n",
        "      checkpoint = torch.load(PATH)\n",
        "    else:\n",
        "      checkpoint = torch.load(PATH, map_location=lambda storage, loc: storage)\n",
        "              \n",
        "    generator.load_state_dict(checkpoint['state_dict_generator'])\n",
        "    discriminator.load_state_dict(checkpoint['state_dict_discriminator'])\n",
        "    gen_optimizer.load_state_dict(checkpoint['gen_optimizer'])\n",
        "    dis_optimizer.load_state_dict(checkpoint['dis_optimizer'])\n",
        "    metrics=checkpoint['metrics']\n",
        "    num_epochs=checkpoint['train_epoch']\n",
        "    date=checkpoint['date']\n",
        "    generator.train(mode=False)\n",
        "    discriminator.train(mode=False)\n",
        "    print('GAN loaded for epochs: ', num_epochs)\n",
        "    print(generator)\n",
        "    print(discriminator)\n",
        "    print(gen_optimizer)\n",
        "    print(dis_optimizer)\n",
        "    print(date)\n",
        "    #test1(generator, discriminator, num_epochs, metrics)\n",
        "else:\n",
        "    if TRAIN_ALL:\n",
        "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                                  shuffle=True)\n",
        "        train_gan(generator, discriminator, gen_optimizer, dis_optimizer, train_loader,\n",
        "                  num_epochs, metrics)\n",
        "        test2(generator, discriminator, num_epochs, metrics, train_loader)\n",
        "    else:\n",
        "        # idx = []\n",
        "        # idx = get_indices(train_set, 4, idx) #second argument is 0 for covid; 1 for normal; 2 for pneumonia_bacteria; 3 for pneumonia_virus for x-ray dataset\n",
        " \n",
        "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                                  shuffle=True)\n",
        "        mask =[x[1]==0 for x in train_loader.dataset] #here is 0 for covid; 1 for normal; 2 for pneumonia_bacteria; 3 for pneumonia_virus for x-ray dataset\n",
        "        idx= np.arange(len(train_loader.dataset))[mask]\n",
        "\n",
        "        print(\"Total samples now are \",len(idx))\n",
        "        selected_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                                      sampler = SubsetRandomSampler(idx))\n",
        "        train_gan(generator, discriminator, gen_optimizer, dis_optimizer, selected_loader,\n",
        "                  num_epochs, metrics)\n",
        "        test2(generator, discriminator, num_epochs, metrics, selected_loader)\n",
        "        test1(generator, discriminator, num_epochs, metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 17] File exists: './augGAN'\n",
            "[Errno 17] File exists: './augGAN/model'\n",
            "[Errno 17] File exists: './augGAN/plots'\n",
            "[Errno 17] File exists: './augGAN/output_images'\n",
            "GAN loaded for epochs:  200\n",
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (9): Dropout(p=0.5, inplace=False)\n",
            "    (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): Dropout(p=0.25, inplace=False)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (14): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (15): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.5, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.002\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.5, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0002\n",
            "    weight_decay: 0\n",
            ")\n",
            "2020-08-23_14:18:41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Zz7NErSjEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "5044b9ed-2c23-4fd8-9fa1-6f495beb3f17"
      },
      "source": [
        "#Testing cell....to visualize \n",
        "test_batch = 1 #No of images to be genertaed in stack \n",
        "test_fake_id = 1 #To generate fake images or just view real images\n",
        "LOAD_ID = 0 #Class of images in case test_fake_id is 0\n",
        "\n",
        "if test_fake_id:\n",
        "  #check for fake image\n",
        "  test_img_list = []\n",
        "  test_noise = torch.randn(test_batch, nz, 1, 1, device=device)\n",
        "  test_img = generator(test_noise)#.detach().cpu()\n",
        "\n",
        "else:\n",
        "  #check for real image\n",
        "  idx = []\n",
        "  #train_set = datasets.ImageFolder(\"main_folder/100/\", transform=transform)\n",
        "  idx = get_indices(train_set, LOAD_ID, idx) \n",
        "  test_loader = torch.utils.data.DataLoader(train_set, batch_size=test_batch,\n",
        "                                                sampler = SubsetRandomSampler(idx))\n",
        "  data = next(iter(test_loader))\n",
        "  test_noise, test_class_lable = data\n",
        "  test_img.data.resize_(test_noise.size()).copy_(test_noise)\n",
        "  #print(data[0].size())\n",
        "  print('class label for real', test_class_lable)\n",
        "\n",
        "s_output = discriminator(test_img.detach().to(device))\n",
        "print('Discriminator s o/p', s_output)\n",
        "\n",
        "test_img = test_img.detach().cpu()\n",
        "test_img_list.append(vutils.make_grid(test_img, padding=2, normalize=True))\n",
        "plt.axis('off')\n",
        "plt.imshow(np.transpose(test_img_list[-1],(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Samples of class 0 found are 60\n",
            "class label for real tensor([0])\n",
            "Discriminator s o/p tensor([[[[0.4945]]]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6058916b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpf-AsWkqzZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df8ffdac-678a-42f9-b83f-cf06a500deed"
      },
      "source": [
        "test_fake(generator, discriminator, metrics, 500, \"normal\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Block.........\n",
            "Discriminator_mean:  0.5166683793067932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_RDk-5_izjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "671b61ee-3715-40ad-e821-c06b8a89ce00"
      },
      "source": [
        "#To confimr no of images in a specified class\n",
        "path, dirs, files = next(os.walk(os.path.join(data_dir, \"train/pneumonia_vir\")))\n",
        "print(len(files))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8la1EFeB3zRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c864d9ed-c889-4244-a5c4-db51946ca646"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(generator, (100, 1, 1))\n",
        "summary(discriminator, (1, 64, 64))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Sequential: 1-1                        [-1, 1, 64, 64]           --\n",
            "|    └─ConvTranspose2d: 2-1              [-1, 512, 4, 4]           819,200\n",
            "|    └─BatchNorm2d: 2-2                  [-1, 512, 4, 4]           1,024\n",
            "|    └─ReLU: 2-3                         [-1, 512, 4, 4]           --\n",
            "|    └─ConvTranspose2d: 2-4              [-1, 256, 8, 8]           2,097,152\n",
            "|    └─BatchNorm2d: 2-5                  [-1, 256, 8, 8]           512\n",
            "|    └─ReLU: 2-6                         [-1, 256, 8, 8]           --\n",
            "|    └─ConvTranspose2d: 2-7              [-1, 128, 16, 16]         524,288\n",
            "|    └─BatchNorm2d: 2-8                  [-1, 128, 16, 16]         256\n",
            "|    └─ReLU: 2-9                         [-1, 128, 16, 16]         --\n",
            "|    └─ConvTranspose2d: 2-10             [-1, 64, 32, 32]          131,072\n",
            "|    └─BatchNorm2d: 2-11                 [-1, 64, 32, 32]          128\n",
            "|    └─ReLU: 2-12                        [-1, 64, 32, 32]          --\n",
            "|    └─ConvTranspose2d: 2-13             [-1, 1, 64, 64]           1,024\n",
            "|    └─Tanh: 2-14                        [-1, 1, 64, 64]           --\n",
            "==========================================================================================\n",
            "Total params: 3,574,656\n",
            "Trainable params: 3,574,656\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 423.53\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.91\n",
            "Params size (MB): 13.64\n",
            "Estimated Total Size (MB): 15.54\n",
            "==========================================================================================\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Sequential: 1-1                        [-1, 1, 1, 1]             --\n",
            "|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          1,024\n",
            "|    └─LeakyReLU: 2-2                    [-1, 64, 32, 32]          --\n",
            "|    └─Dropout: 2-3                      [-1, 64, 32, 32]          --\n",
            "|    └─Conv2d: 2-4                       [-1, 128, 16, 16]         131,072\n",
            "|    └─BatchNorm2d: 2-5                  [-1, 128, 16, 16]         256\n",
            "|    └─LeakyReLU: 2-6                    [-1, 128, 16, 16]         --\n",
            "|    └─Conv2d: 2-7                       [-1, 256, 8, 8]           524,288\n",
            "|    └─BatchNorm2d: 2-8                  [-1, 256, 8, 8]           512\n",
            "|    └─LeakyReLU: 2-9                    [-1, 256, 8, 8]           --\n",
            "|    └─Dropout: 2-10                     [-1, 256, 8, 8]           --\n",
            "|    └─Conv2d: 2-11                      [-1, 512, 4, 4]           2,097,152\n",
            "|    └─BatchNorm2d: 2-12                 [-1, 512, 4, 4]           1,024\n",
            "|    └─Dropout: 2-13                     [-1, 512, 4, 4]           --\n",
            "|    └─LeakyReLU: 2-14                   [-1, 512, 4, 4]           --\n",
            "|    └─Conv2d: 2-15                      [-1, 1, 1, 1]             8,192\n",
            "|    └─Sigmoid: 2-16                     [-1, 1, 1, 1]             --\n",
            "==========================================================================================\n",
            "Total params: 2,763,520\n",
            "Trainable params: 2,763,520\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 104.48\n",
            "==========================================================================================\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 1.38\n",
            "Params size (MB): 10.54\n",
            "Estimated Total Size (MB): 11.93\n",
            "==========================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [-1, 1, 1, 1]             --\n",
              "|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          1,024\n",
              "|    └─LeakyReLU: 2-2                    [-1, 64, 32, 32]          --\n",
              "|    └─Dropout: 2-3                      [-1, 64, 32, 32]          --\n",
              "|    └─Conv2d: 2-4                       [-1, 128, 16, 16]         131,072\n",
              "|    └─BatchNorm2d: 2-5                  [-1, 128, 16, 16]         256\n",
              "|    └─LeakyReLU: 2-6                    [-1, 128, 16, 16]         --\n",
              "|    └─Conv2d: 2-7                       [-1, 256, 8, 8]           524,288\n",
              "|    └─BatchNorm2d: 2-8                  [-1, 256, 8, 8]           512\n",
              "|    └─LeakyReLU: 2-9                    [-1, 256, 8, 8]           --\n",
              "|    └─Dropout: 2-10                     [-1, 256, 8, 8]           --\n",
              "|    └─Conv2d: 2-11                      [-1, 512, 4, 4]           2,097,152\n",
              "|    └─BatchNorm2d: 2-12                 [-1, 512, 4, 4]           1,024\n",
              "|    └─Dropout: 2-13                     [-1, 512, 4, 4]           --\n",
              "|    └─LeakyReLU: 2-14                   [-1, 512, 4, 4]           --\n",
              "|    └─Conv2d: 2-15                      [-1, 1, 1, 1]             8,192\n",
              "|    └─Sigmoid: 2-16                     [-1, 1, 1, 1]             --\n",
              "==========================================================================================\n",
              "Total params: 2,763,520\n",
              "Trainable params: 2,763,520\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 104.48\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 1.38\n",
              "Params size (MB): 10.54\n",
              "Estimated Total Size (MB): 11.93\n",
              "=========================================================================================="
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N0yiqHfzOzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9599816b-3707-49c0-c869-932427a16458"
      },
      "source": [
        "print(generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Z61n2SAhlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "671b8da4-7a8b-4136-948f-9b057aa52075"
      },
      "source": [
        "print(discriminator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}